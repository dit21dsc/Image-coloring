{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dit21dsc/Image-coloring/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to G Drive in order to retrieve the image datasets"
      ],
      "metadata": {
        "id": "jg3EZ6ewEwZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FXrwfJVt8t6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load all neccessary libraries "
      ],
      "metadata": {
        "id": "G3E3G_VuE9du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import keras\n",
        "from tensorflow.keras.utils  import array_to_img, img_to_array, load_img\n",
        "from keras.applications.inception_resnet_v2 import preprocess_input\n",
        "from keras.models import Sequential, Model\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "#OPTIMIZER\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import random"
      ],
      "metadata": {
        "id": "wR0n8S5S9K-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ".... Add the Keras.Layers"
      ],
      "metadata": {
        "id": "SOFqNolPFDmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D,BatchNormalization , ReLU , Conv2DTranspose"
      ],
      "metadata": {
        "id": "F2eFkrkB9ln3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All image datasets loaded in numpy arrays"
      ],
      "metadata": {
        "id": "olYC8onDFI9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Gray_DS = np.load(\"/content/drive/MyDrive/gray_scale.npy\")\n",
        "AB_1_NPY = np.load(\"/content/drive/MyDrive/ab1.npy\")\n",
        "AB_2_NPY = np.load(\"/content/drive/MyDrive/ab2.npy\")\n",
        "AB_3_NPY = np.load(\"/content/drive/MyDrive/ab3.npy\")\n",
        "AB_DS = np.concatenate([AB_1_NPY, AB_2_NPY, AB_3_NPY], axis=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "a4AfM8uI9zLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check type and size of arrays "
      ],
      "metadata": {
        "id": "ATDRganUFsVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(Gray_DS))\n",
        "print(type(AB_DS))"
      ],
      "metadata": {
        "id": "1HCj2bBc9870"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Gray_DS.shape)\n",
        "print(AB_DS.shape)"
      ],
      "metadata": {
        "id": "sF_QSFmR99hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pick a subset of the dataset to process due to limited resources"
      ],
      "metadata": {
        "id": "q5UuaOhOFycU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_split = 2000\n",
        "end_split = 2500\n",
        "end_non_seen= 3000\n",
        "dataset_count = 500"
      ],
      "metadata": {
        "id": "ece1iBlt-ADA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next I split the gray records in 2 set ( Train , Hidden ) because I want to keep records hidden by the algorithm. I will use them at the end for algorithm evaluation and prediction of colorized image"
      ],
      "metadata": {
        "id": "HFeqb7e_GNGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_Train = Gray_DS[start_split:end_split,:,:].astype(\"float32\").reshape(dataset_count,Gray_DS.shape[1],Gray_DS.shape[2])"
      ],
      "metadata": {
        "id": "aVYGEZzw-EGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_Hidden = Gray_DS[end_split:end_non_seen,:,:].astype(\"float32\").reshape(dataset_count,Gray_DS.shape[1],Gray_DS.shape[2])"
      ],
      "metadata": {
        "id": "IPQvkD9Q-GMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_Train = AB_DS[start_split:end_split,:,:].astype(\"float32\")"
      ],
      "metadata": {
        "id": "q0lyXRzo-ILr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_Train.shape)\n",
        "print(X_Hidden.shape)\n",
        "print(Y_Train.shape)"
      ],
      "metadata": {
        "id": "Qv9cjEHf-KLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to convert the input image to row"
      ],
      "metadata": {
        "id": "1OXXw76qRoC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_image_to_row(gray_img,splitting=dataset_count,inp_function=preprocess_input):\n",
        "    Empty_imp = np.zeros((splitting,224,224,3))\n",
        "    for indexing in range(0,3):\n",
        "        Empty_imp[:splitting,:,:,indexing] = gray_img[:splitting]\n",
        "        \n",
        "    return inp_function(Empty_imp)"
      ],
      "metadata": {
        "id": "MXfLy7IL-L5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Inp_Img = conv_image_to_row(X_Train,dataset_count)\n",
        "\n",
        "Hidden_inp = conv_image_to_row(X_Hidden,dataset_count)\n",
        "\n"
      ],
      "metadata": {
        "id": "_3ZS06vB-NnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Inp_Img.shape)\n",
        "print(Hidden_inp.shape)"
      ],
      "metadata": {
        "id": "tqDSuz2s-Pa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function transform the input image by L*a*b color space to RGB color space because all images in dataset are stored as LAB"
      ],
      "metadata": {
        "id": "1PdvHoyHaTEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tranf_lab_to_rgb(gray_img,ab_images,n=10):\n",
        "    Empty_imp = np.zeros((n,224,224,3))\n",
        "    \n",
        "    Empty_imp[:,:,:,0] = gray_img[0:n:]\n",
        "    Empty_imp[:,:,:,1:] = ab_images[0:n:]\n",
        "    \n",
        "    Empty_imp = Empty_imp.astype(\"uint8\")\n",
        "    \n",
        "    Main_Img = []\n",
        "    \n",
        "    for indexing in range(0,n):\n",
        "        Main_Img.append(cv2.cvtColor(Empty_imp[indexing],cv2.COLOR_LAB2RGB))\n",
        "        \n",
        "    Main_Img = np.array(Main_Img)\n",
        "    \n",
        "    return Main_Img"
      ],
      "metadata": {
        "id": "sU7n7YY5-Rcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All images are stored as L*A*B* format so we use the function COLOR_LAB2RGB to generate the RGB image"
      ],
      "metadata": {
        "id": "ohrh-K_X4Dwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Output_img = preprocess_input(tranf_lab_to_rgb(X_Train,Y_Train,n=dataset_count))\n",
        "print(Output_img.shape)"
      ],
      "metadata": {
        "id": "VckwcgDA-Uro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Gray_emp_imp = np.zeros((dataset_count,Gray_DS.shape[1],Gray_DS.shape[2],1))\n",
        "Gray_emp_imp[:,:,:,0] = X_Train\n",
        "print(Gray_emp_imp.shape)"
      ],
      "metadata": {
        "id": "uKtNn_Qo-WuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup CNN model's parameters"
      ],
      "metadata": {
        "id": "wY5LgyATbS62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compile_loss = \"mse\"\n",
        "compile_optimizer = RMSprop(learning_rate=0.0001,decay=1e-8)\n",
        "compile_metrics = [\"accuracy\"]\n",
        "input_dim = (Inp_Img.shape[1],Inp_Img.shape[2],Inp_Img.shape[3])\n",
        "output_class = 1"
      ],
      "metadata": {
        "id": "4pe6UzqR-ZMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Stopper = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=3,mode=\"min\")\n",
        "Checkpoint = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\",\n",
        "                                                      save_best_only=True,\n",
        "                                                      save_weights_only=True,\n",
        "                                                      filepath=\"./modelcheck\")"
      ],
      "metadata": {
        "id": "9cYCNvq2-avY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup the CNN layers"
      ],
      "metadata": {
        "id": "ia3cwolXSM5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Enc_Gray = Sequential()\n",
        "Enc_Gray.add(Conv2D(32,(2,2),kernel_initializer = 'he_normal',padding = \"same\",use_bias = True))\n",
        "Enc_Gray.add(BatchNormalization())\n",
        "Enc_Gray.add(ReLU())"
      ],
      "metadata": {
        "id": "jKZ3BDNp-cyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Enc_Gray.add(Conv2D(64,(2,2),kernel_initializer = 'he_normal',padding = \"same\",use_bias = True))\n",
        "Enc_Gray.add(BatchNormalization())\n",
        "Enc_Gray.add(ReLU())\n",
        "#"
      ],
      "metadata": {
        "id": "ekipuEu6-e1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Enc_Gray.add(Conv2D(128,(2,2),kernel_initializer = 'he_normal',padding = \"same\",use_bias = True))\n",
        "Enc_Gray.add(BatchNormalization())\n",
        "Enc_Gray.add(ReLU())\n"
      ],
      "metadata": {
        "id": "UA6xR-2H-gwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Enc_Gray.add(Conv2D(256,(2,2),kernel_initializer = 'he_normal',padding = \"same\",use_bias = True))\n",
        "Enc_Gray.add(BatchNormalization())\n",
        "Enc_Gray.add(ReLU())"
      ],
      "metadata": {
        "id": "B7QkpT10-kdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dec_Gray = Sequential()\n",
        "Dec_Gray.add(Conv2DTranspose(128,(2,2),padding = \"same\",use_bias = True))\n",
        "Dec_Gray.add(ReLU())\n",
        "#"
      ],
      "metadata": {
        "id": "JYP5R2px-nrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dec_Gray.add(Conv2DTranspose(64,(2,2),padding = \"same\",use_bias = True))\n",
        "Dec_Gray.add(ReLU())\n",
        "#"
      ],
      "metadata": {
        "id": "vEgDzoKc-oGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dec_Gray.add(Conv2DTranspose(32,(2,2),padding = \"same\",use_bias = True))\n",
        "Dec_Gray.add(ReLU())\n",
        "#"
      ],
      "metadata": {
        "id": "yzUHRatl-pz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dec_Gray.add(Conv2DTranspose(3,(2,2),padding = \"same\",use_bias = True))\n",
        "Dec_Gray.add(ReLU())"
      ],
      "metadata": {
        "id": "ABX0KpTt-tZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the training of the model"
      ],
      "metadata": {
        "id": "9m0OwqTS05nU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Exec_Encoder = Sequential([Enc_Gray,Dec_Gray])\n",
        "Exec_Encoder.compile(loss=compile_loss,optimizer=compile_optimizer,metrics=compile_metrics)\n",
        "Exec_Encoder_Model = Exec_Encoder.fit(Inp_Img,Output_img,epochs=25,callbacks=[Stopper,Checkpoint],batch_size=4)"
      ],
      "metadata": {
        "id": "-TN0HOnA-t9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate list of images by using the trained model for the known and the unknown dataset of images"
      ],
      "metadata": {
        "id": "1fk1ByKi0rz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PREDICTION\n",
        "\n",
        "Predict_img = Exec_Encoder.predict(Inp_Img[0:100])\n",
        "Predict_Hidden = Exec_Encoder.predict(Hidden_inp[0:100])\n"
      ],
      "metadata": {
        "id": "W3utWZs1RioD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the trained model with the hidden dataset "
      ],
      "metadata": {
        "id": "HvEtx1Wj0aj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "figure,axis = plt.subplots(1,2,figsize=(20,20))\n",
        "img_number =  random.randint(0,99)\n",
        "\n",
        "Original_Img = Hidden_inp[img_number]\n",
        "Predict_Image_AE = Predict_Hidden[img_number]\n",
        "axis[0].imshow(Original_Img)\n",
        "axis[0].set_xlabel(Original_Img.shape)\n",
        "axis[0].set_ylabel(Original_Img.size)\n",
        "axis[0].set_title(\"INPUT\")\n",
        "axis[1].imshow(Predict_Image_AE)\n",
        "axis[1].set_xlabel(Predict_Image_AE.shape)\n",
        "axis[1].set_ylabel(Predict_Image_AE.size)\n",
        "axis[1].set_title(\"COLORIZED OUTPUT\")\n"
      ],
      "metadata": {
        "id": "LhMQE5zpRpti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the trained model with the dataset used for its training "
      ],
      "metadata": {
        "id": "xOLymzFl0i32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "figure,axis = plt.subplots(1,2,figsize=(20,20))\n",
        "img_number =  random.randint(0,99)\n",
        "\n",
        "Original_Img = Inp_Img[img_number]\n",
        "Predict_Image_AE = Predict_img[img_number]\n",
        "axis[0].imshow(Original_Img)\n",
        "axis[0].set_xlabel(Original_Img.shape)\n",
        "axis[0].set_ylabel(Original_Img.size)\n",
        "axis[0].set_title(\"INPUT\")\n",
        "axis[1].imshow(Predict_Image_AE)\n",
        "axis[1].set_xlabel(Predict_Image_AE.shape)\n",
        "axis[1].set_ylabel(Predict_Image_AE.size)\n",
        "axis[1].set_title(\"COLORIZED OUTPUT\")"
      ],
      "metadata": {
        "id": "Oh3C-Vrlz2te"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Main",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}